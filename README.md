# BAttGAND

An official implementation code for paper "Black-Box Attack against GAN-Generated Image Detector with Contrastive Perturbation"

## Background
The emergence of visually realistic GAN-generated facial images has raised concerns regarding potential misuse. In response, effective forensic algorithms have been developed to detect such synthetic images in recent years. However, the vulnerability of such forensic detectors to adversarial attacks remains an important issue that requires further investigation. In this paper, we propose a new black-box attack method against GAN-generated image detectors. It involves contrastive learning strategy to train an encoderâ€“decoder anti-forensic network with a contrastive loss function. GAN-generated and corresponding simulated real images are constructed as positive and negative samples, respectively. By leveraging the trained attack model, we can apply imperceptible perturbation to input synthetic images for removing GAN fingerprint to some extent. GAN-generated image detectors may be deceived consequently. Extensive experimental results demonstrate that the proposed attack effectively reduces the accuracy of three state-of-the-art detectors on six popular GANs, while also achieving high visual quality of the attacked images.

<p align='center'>  
  <img src='./images/Fig.1.png' width='870'/>
</p>
<p align='center'>  
  <em>Framework of BAttGAND.</em>
</p>

## Qualitative Evaluation Results

<p align='center'>  
  <img src='./images/Fig.2.png' width='870'/>
</p>
<p align='center'>  
  <em>The visual examples of GAN-generated images, corresponding attacked images under different attack methods. a, b, c, d, e, f is from ProGAN, StarGAN, StarGAN2, StyleGAN, StyleGAN2 and StyleGAN3, respectively.</em>
</p>




## Dependency
- torch 1.7.0
- python 3.7

## GAN-Generated Image Detectors

[Wang detector](https://github.com/PeterWang512/CNNDetection): It is ResNet50 network trained on ProGAN and real image samples with strong data enhancement including compression and blur, which improves the generalization capability and robustness of detection.

[Gragnaniello detector](https://github.com/grip-unina/GANimageDetection): It uses a variant Resnet50 backbone trained on ProGAN and real image samples with various types of content, such as animals, paintings and human faces. Its generalization performance is further improved with a suitable training strategy and network architectural changes, for example, removing the downsampling operation in the first layer. 

[Kitware detector](https://github.com/Kitware/generated-image-detection): It is trained on StyleGAN2 and real images. Varied image representations (raw pixels and residual images) and deep learning backbones (ResNet, EfficientNet and VGG are compared experimentally and their performance keep approximate. Finally, ResNet101 is applied as backbone network in the Kitware detector. 

## Test dataset
the test dataset is collected with total 36,000 face images generated by 6 different GANs, therein 6,000 samples for each. The [StyleGAN](https://github.com/NVlabs/stylegan), [StyleGAN2](https://github.com/NVlabs/stylegan2) and [ProGAN](https://github.com/tkarras/progressive_growing_of_gans) images are downloaded from the public datasets shared by Nvidia Research Lab. The [StarGAN](https://github.com/yunjey/stargan), [StarGAN2](https://github.com/clovaai/stargan-v2) and [StyleGAN3](https://github.com/NVlabs/stylegan3) images are created by public pre-trained generators.


## Usage

For example to train theBAttGAND:
```bash
python train.py
```

For example to test theBAttGAND:
```bash
python test.py
```


## Citation
If you use this code for your research, please cite our paper
```
@article{lou2023black,
  title={Black-box attack against GAN-generated image detector with contrastive perturbation},
  author={Lou, Zijie and Cao, Gang and Lin, Man},
  journal={Engineering Applications of Artificial Intelligence},
  volume={124},
  pages={106594},
  year={2023},
  publisher={Elsevier}
}
```

## Contact

If you have any question, please feel free to contact us via `louzijie2022@163.com`.

## License
Licensed under a [Creative Commons Attribution-NonCommercial 4.0 International](https://creativecommons.org/licenses/by-nc/4.0/) for Non-commercial use only.
Any commercial use should get formal permission first.